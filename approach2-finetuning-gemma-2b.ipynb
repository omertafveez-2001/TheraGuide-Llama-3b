{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:21:02.486658Z","iopub.execute_input":"2024-04-27T15:21:02.487395Z","iopub.status.idle":"2024-04-27T15:21:02.497858Z","shell.execute_reply.started":"2024-04-27T15:21:02.487365Z","shell.execute_reply":"2024-04-27T15:21:02.496853Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### **Installing Dependencies and Libraries**","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install transformers trl datasets accelerate bitsandbytes peft","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-27T15:21:03.629536Z","iopub.execute_input":"2024-04-27T15:21:03.630304Z","iopub.status.idle":"2024-04-27T15:21:22.066553Z","shell.execute_reply.started":"2024-04-27T15:21:03.630277Z","shell.execute_reply":"2024-04-27T15:21:22.065514Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### **Logging in HuggingFace**","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:21:22.068493Z","iopub.execute_input":"2024-04-27T15:21:22.069167Z","iopub.status.idle":"2024-04-27T15:21:22.338656Z","shell.execute_reply.started":"2024-04-27T15:21:22.069128Z","shell.execute_reply":"2024-04-27T15:21:22.337737Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a21dfbabaaea4a87a0837fe72d12184c"}},"metadata":{}}]},{"cell_type":"markdown","source":"## **Loading Data and Preprocessing Data**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset1 = load_dataset(\"Amod/mental_health_counseling_conversations\")\ndataset2 = load_dataset(\"nbertagnolli/counsel-chat\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:03:17.199243Z","iopub.execute_input":"2024-04-27T20:03:17.200220Z","iopub.status.idle":"2024-04-27T20:03:19.800407Z","shell.execute_reply.started":"2024-04-27T20:03:17.200186Z","shell.execute_reply":"2024-04-27T20:03:19.799660Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stderr","text":"Repo card metadata block was not found. Setting CardData to empty.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf1 = pd.DataFrame(dataset1[\"train\"])\ndf2 = pd.DataFrame(dataset2[\"train\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:03:21.004943Z","iopub.execute_input":"2024-04-27T20:03:21.005350Z","iopub.status.idle":"2024-04-27T20:03:21.536501Z","shell.execute_reply.started":"2024-04-27T20:03:21.005319Z","shell.execute_reply":"2024-04-27T20:03:21.535425Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"df3 = df2[[\"questionText\", \"answerText\"]]\ndf3 = df3.rename(columns={\"questionText\":\"Context\", \"answerText\":\"Response\"})\ndf3.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:03:21.538125Z","iopub.execute_input":"2024-04-27T20:03:21.538408Z","iopub.status.idle":"2024-04-27T20:03:21.550892Z","shell.execute_reply.started":"2024-04-27T20:03:21.538385Z","shell.execute_reply":"2024-04-27T20:03:21.549899Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"                                             Context  \\\n0  I have so many issues to address. I have a his...   \n1  I have so many issues to address. I have a his...   \n2  I have so many issues to address. I have a his...   \n3  I have so many issues to address. I have a his...   \n4  I have so many issues to address. I have a his...   \n\n                                            Response  \n0  It is very common for people to have multiple ...  \n1  I've never heard of someone having \"too many i...  \n2  Absolutely not.  I strongly recommending worki...  \n3  Let me start by saying there are never too man...  \n4  I just want to acknowledge you for the courage...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>It is very common for people to have multiple ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>I've never heard of someone having \"too many i...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>Absolutely not.  I strongly recommending worki...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>Let me start by saying there are never too man...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>I just want to acknowledge you for the courage...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"final_df = pd.concat([df3, df1], axis=0)\nfinal_df[\"instructions\"] = '''Given the Patient's Context, provide Response that has a diagnosis of the Patient'''\nfinal_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:03:21.552121Z","iopub.execute_input":"2024-04-27T20:03:21.552451Z","iopub.status.idle":"2024-04-27T20:03:21.570362Z","shell.execute_reply.started":"2024-04-27T20:03:21.552425Z","shell.execute_reply":"2024-04-27T20:03:21.569560Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"                                             Context  \\\n0  I have so many issues to address. I have a his...   \n1  I have so many issues to address. I have a his...   \n2  I have so many issues to address. I have a his...   \n3  I have so many issues to address. I have a his...   \n4  I have so many issues to address. I have a his...   \n\n                                            Response  \\\n0  It is very common for people to have multiple ...   \n1  I've never heard of someone having \"too many i...   \n2  Absolutely not.  I strongly recommending worki...   \n3  Let me start by saying there are never too man...   \n4  I just want to acknowledge you for the courage...   \n\n                                        instructions  \n0  Given the Patient's Context, provide Response ...  \n1  Given the Patient's Context, provide Response ...  \n2  Given the Patient's Context, provide Response ...  \n3  Given the Patient's Context, provide Response ...  \n4  Given the Patient's Context, provide Response ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context</th>\n      <th>Response</th>\n      <th>instructions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>It is very common for people to have multiple ...</td>\n      <td>Given the Patient's Context, provide Response ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>I've never heard of someone having \"too many i...</td>\n      <td>Given the Patient's Context, provide Response ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>Absolutely not.  I strongly recommending worki...</td>\n      <td>Given the Patient's Context, provide Response ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>Let me start by saying there are never too man...</td>\n      <td>Given the Patient's Context, provide Response ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I have so many issues to address. I have a his...</td>\n      <td>I just want to acknowledge you for the courage...</td>\n      <td>Given the Patient's Context, provide Response ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Final Length of the dataframe: {len(final_df)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:03:21.812099Z","iopub.execute_input":"2024-04-27T20:03:21.812843Z","iopub.status.idle":"2024-04-27T20:03:21.818431Z","shell.execute_reply.started":"2024-04-27T20:03:21.812812Z","shell.execute_reply":"2024-04-27T20:03:21.816608Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Final Length of the dataframe: 6287\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(final_df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:03:22.132506Z","iopub.execute_input":"2024-04-27T20:03:22.133245Z","iopub.status.idle":"2024-04-27T20:03:22.141482Z","shell.execute_reply.started":"2024-04-27T20:03:22.133213Z","shell.execute_reply":"2024-04-27T20:03:22.140638Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"print(f\"Length of training set: {len(train_df)}\")\nprint(f\"Length of testing set: {len(test_df)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:03:22.461414Z","iopub.execute_input":"2024-04-27T20:03:22.461799Z","iopub.status.idle":"2024-04-27T20:03:22.466972Z","shell.execute_reply.started":"2024-04-27T20:03:22.461771Z","shell.execute_reply":"2024-04-27T20:03:22.465891Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Length of training set: 5029\nLength of testing set: 1258\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\nconversation_train = Dataset.from_pandas(train_df[:3000])\nconversation_test = Dataset.from_pandas(test_df[:500])","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:03:22.812736Z","iopub.execute_input":"2024-04-27T20:03:22.813146Z","iopub.status.idle":"2024-04-27T20:03:22.875382Z","shell.execute_reply.started":"2024-04-27T20:03:22.813117Z","shell.execute_reply":"2024-04-27T20:03:22.874565Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"print(conversation_train)\nprint(conversation_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:03:23.153095Z","iopub.execute_input":"2024-04-27T20:03:23.153957Z","iopub.status.idle":"2024-04-27T20:03:23.158572Z","shell.execute_reply.started":"2024-04-27T20:03:23.153926Z","shell.execute_reply":"2024-04-27T20:03:23.157446Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['Context', 'Response', 'instructions', '__index_level_0__'],\n    num_rows: 3000\n})\nDataset({\n    features: ['Context', 'Response', 'instructions', '__index_level_0__'],\n    num_rows: 500\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Creating a Gemma Prompt Template**","metadata":{}},{"cell_type":"code","source":"def formatting_func(example):\n    text = f\"<start_of_turn>user\\n{example['Context'][0]}\\n{example['instructions'][0]}\\n<end_of_turn> <start_of_turn>model\\n{example['Response'][0]}<end_of_turn>\"\n    return [text]","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:04:50.756221Z","iopub.execute_input":"2024-04-27T20:04:50.756758Z","iopub.status.idle":"2024-04-27T20:04:50.764337Z","shell.execute_reply.started":"2024-04-27T20:04:50.756727Z","shell.execute_reply":"2024-04-27T20:04:50.763379Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"## **Loading Gemma Model using Quantization**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GemmaTokenizer\nmodel_id = \"google/gemma-2b\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer=AutoTokenizer.from_pretrained(model_id)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    use_cache=False,\n    use_flash_attention_2=False,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n)\n\nmodel.config.pretraining_tp=1","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:04:54.623779Z","iopub.execute_input":"2024-04-27T20:04:54.624696Z","iopub.status.idle":"2024-04-27T20:05:02.025020Z","shell.execute_reply.started":"2024-04-27T20:04:54.624662Z","shell.execute_reply":"2024-04-27T20:05:02.024175Z"},"trusted":true},"execution_count":82,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d35a0c515ce4c72ba7f49068d6a7a05"}},"metadata":{}}]},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training, get_peft_model\nmodel = prepare_model_for_kbit_training(model)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:06:29.801833Z","iopub.execute_input":"2024-04-27T20:06:29.802265Z","iopub.status.idle":"2024-04-27T20:06:29.815666Z","shell.execute_reply.started":"2024-04-27T20:06:29.802233Z","shell.execute_reply":"2024-04-27T20:06:29.814666Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"GemmaForCausalLM(\n  (model): GemmaModel(\n    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n    (layers): ModuleList(\n      (0-17): 18 x GemmaDecoderLayer(\n        (self_attn): GemmaSdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): GemmaRotaryEmbedding()\n        )\n        (mlp): GemmaMLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n          (down_proj): Linear4bit(in_features=16384, out_features=2048, bias=False)\n          (act_fn): PytorchGELUTanh()\n        )\n        (input_layernorm): GemmaRMSNorm()\n        (post_attention_layernorm): GemmaRMSNorm()\n      )\n    )\n    (norm): GemmaRMSNorm()\n  )\n  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig\n\nlora_config= LoraConfig(\n    r=8,\n    lora_dropout=0.1,\n    lora_alpha=16,\n    bias=\"none\",\n    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    task_type=\"CAUSAL_LM\",\n)\n\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:06:37.099120Z","iopub.execute_input":"2024-04-27T20:06:37.099764Z","iopub.status.idle":"2024-04-27T20:06:37.377014Z","shell.execute_reply.started":"2024-04-27T20:06:37.099732Z","shell.execute_reply":"2024-04-27T20:06:37.375792Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"## **Comparison in the number of params between original and quantized model**","metadata":{}},{"cell_type":"code","source":"trainable, total = model.get_nb_trainable_parameters()\nprint(f\"Trainable: {trainable}\\nTotal: {total}\\nPercentage: {trainable/total*100:.4f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:06:40.038751Z","iopub.execute_input":"2024-04-27T20:06:40.039142Z","iopub.status.idle":"2024-04-27T20:06:40.051262Z","shell.execute_reply.started":"2024-04-27T20:06:40.039112Z","shell.execute_reply":"2024-04-27T20:06:40.050310Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Trainable: 9805824\nTotal: 2515978240\nPercentage: 0.3897%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Training**","metadata":{}},{"cell_type":"code","source":"import transformers\n\nfrom trl import SFTTrainer\n\ntokenizer.pad_token = tokenizer.eos_token\ntorch.cuda.empty_cache()\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=conversation_train,\n    eval_dataset=conversation_test,\n    #dataset_text_field=\"prompt\",\n    peft_config=lora_config,\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=4,\n        warmup_steps=0.03,\n        max_steps=1000,\n        learning_rate=2e-4,\n        logging_steps=10,\n        output_dir=\"outputs\",\n        optim=\"paged_adamw_8bit\",\n        save_strategy=\"no\",\n        report_to=\"tensorboard\",\n    ),\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n    formatting_func=formatting_func,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:06:59.864220Z","iopub.execute_input":"2024-04-27T20:06:59.864636Z","iopub.status.idle":"2024-04-27T20:07:02.221669Z","shell.execute_reply.started":"2024-04-27T20:06:59.864608Z","shell.execute_reply":"2024-04-27T20:07:02.220810Z"},"trusted":true},"execution_count":87,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9682e08f471440b0b59ba0d4edee695e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77c05d270f5a4d56ada9832d2e9b67ed"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T20:07:05.902220Z","iopub.execute_input":"2024-04-27T20:07:05.902628Z","iopub.status.idle":"2024-04-27T20:56:38.911486Z","shell.execute_reply.started":"2024-04-27T20:07:05.902598Z","shell.execute_reply":"2024-04-27T20:56:38.910566Z"},"trusted":true},"execution_count":88,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 49:27, Epoch 666/1000]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.298600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.713400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.186700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.054500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.041600</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.040300</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.037100</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.034400</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.033400</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.030500</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.030000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.030100</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.029200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.029500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.028300</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.028400</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.028500</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.028100</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.027600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.028400</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.027700</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.028200</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.026600</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.028000</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.027800</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.026300</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.027800</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.027700</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.027100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.026800</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.027000</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.027700</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.026900</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.026800</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.026400</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.027100</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.026200</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.027000</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.026400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.026900</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.025400</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.026800</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.026800</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.026700</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.026700</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.026100</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.025700</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.025700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.026000</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.026600</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.026000</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.025600</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.026400</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.026400</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.025000</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.026400</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.025600</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.026600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.025500</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.026300</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.025500</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.025800</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.025800</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.025400</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.026300</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.025700</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.026000</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.025700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.025700</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.026200</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.025400</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.026500</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.025400</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.026200</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.025600</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.026200</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.024700</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.026200</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.026200</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.025600</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.026400</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.025600</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.026100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.025600</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.026200</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.026400</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.025600</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.026100</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.026100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1000, training_loss=0.04851990021765232, metrics={'train_runtime': 2971.9706, 'train_samples_per_second': 1.346, 'train_steps_per_second': 0.336, 'total_flos': 1.024292033359872e+16, 'train_loss': 0.04851990021765232, 'epoch': 666.67})"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Pushing the model to HuggingFace**","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:00:57.322474Z","iopub.execute_input":"2024-04-27T21:00:57.323302Z","iopub.status.idle":"2024-04-27T21:00:57.344966Z","shell.execute_reply.started":"2024-04-27T21:00:57.323271Z","shell.execute_reply":"2024-04-27T21:00:57.344019Z"},"trusted":true},"execution_count":89,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f7409fe57a64cb2bfc475a9d9de7535"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.model.push_to_hub(repo_id=\"omertafveez/Gemma-TherapyChatBot\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:01:22.034335Z","iopub.execute_input":"2024-04-27T21:01:22.035012Z","iopub.status.idle":"2024-04-27T21:01:25.788510Z","shell.execute_reply.started":"2024-04-27T21:01:22.034979Z","shell.execute_reply":"2024-04-27T21:01:25.787587Z"},"trusted":true},"execution_count":90,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/39.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c68964df724440186542d0fb16ee0de"}},"metadata":{}},{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/omertafveez/Gemma-TherapyChatBot/commit/f154ded9bc6ceac82b8a0da53198906f4cbac3be', commit_message='Upload model', commit_description='', oid='f154ded9bc6ceac82b8a0da53198906f4cbac3be', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"model_id = \"google/gemma-2b\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    use_cache=False,\n    use_flash_attention_2=False,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:01:52.699214Z","iopub.execute_input":"2024-04-27T21:01:52.699626Z","iopub.status.idle":"2024-04-27T21:01:58.579791Z","shell.execute_reply.started":"2024-04-27T21:01:52.699594Z","shell.execute_reply":"2024-04-27T21:01:58.578833Z"},"trusted":true},"execution_count":91,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3654a2d2e4d4a32bd90aedf6680b777"}},"metadata":{}}]},{"cell_type":"code","source":"from peft import PeftModel\n\nadapter_model = PeftModel.from_pretrained(model, \"omertafveez/Gemma-TherapyChatBot\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:02:13.013793Z","iopub.execute_input":"2024-04-27T21:02:13.014172Z","iopub.status.idle":"2024-04-27T21:02:14.500632Z","shell.execute_reply.started":"2024-04-27T21:02:13.014143Z","shell.execute_reply":"2024-04-27T21:02:14.499794Z"},"trusted":true},"execution_count":92,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/716 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55e39ec2247d48438c5d29a7629a53fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/39.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8179f906652a44b49dd88d1cc1b615a7"}},"metadata":{}}]},{"cell_type":"code","source":"model2 = adapter_model.merge_and_unload()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:02:21.985769Z","iopub.execute_input":"2024-04-27T21:02:21.986550Z","iopub.status.idle":"2024-04-27T21:02:30.471735Z","shell.execute_reply.started":"2024-04-27T21:02:21.986509Z","shell.execute_reply":"2024-04-27T21:02:30.470908Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"model2.push_to_hub(repo_id=\"omertafveez/Gemma-TherapyChatBot\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:02:32.873430Z","iopub.execute_input":"2024-04-27T21:02:32.874234Z","iopub.status.idle":"2024-04-27T21:03:32.795774Z","shell.execute_reply.started":"2024-04-27T21:02:32.874203Z","shell.execute_reply":"2024-04-27T21:03:32.794726Z"},"trusted":true},"execution_count":94,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b3d4d885124e448d40a0cf3948bde0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d542d3f90c45c6a0c3364f45d558cb"}},"metadata":{}},{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/omertafveez/Gemma-TherapyChatBot/commit/6b87a8d0b46e79f8413e0d215c4b5c6182ae426a', commit_message='Upload GemmaForCausalLM', commit_description='', oid='6b87a8d0b46e79f8413e0d215c4b5c6182ae426a', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.push_to_hub(repo_id=\"omertafveez/Gemma-TherapyChatBot\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:03:37.787919Z","iopub.execute_input":"2024-04-27T21:03:37.788746Z","iopub.status.idle":"2024-04-27T21:03:44.742579Z","shell.execute_reply.started":"2024-04-27T21:03:37.788715Z","shell.execute_reply":"2024-04-27T21:03:44.741362Z"},"trusted":true},"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a38744b9c6f4c88b3621a55354b7fee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"858dbf77b1f241d29295acea4b29bd4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc6c124fd473430aaa373808032cc33b"}},"metadata":{}},{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/omertafveez/Gemma-TherapyChatBot/commit/48e05412ec532766fe9b589290bdf2fba40d4c38', commit_message='Upload tokenizer', commit_description='', oid='48e05412ec532766fe9b589290bdf2fba40d4c38', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Inference**","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:03:54.760891Z","iopub.execute_input":"2024-04-27T21:03:54.761576Z","iopub.status.idle":"2024-04-27T21:03:54.784284Z","shell.execute_reply.started":"2024-04-27T21:03:54.761542Z","shell.execute_reply":"2024-04-27T21:03:54.783243Z"},"trusted":true},"execution_count":96,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f341c9c61d543be9d6b93df61cf5d1b"}},"metadata":{}}]},{"cell_type":"code","source":"model_id = \"omertafveez/Gemma-TherapyChatBot\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:04:18.577302Z","iopub.execute_input":"2024-04-27T21:04:18.578151Z","iopub.status.idle":"2024-04-27T21:04:18.584051Z","shell.execute_reply.started":"2024-04-27T21:04:18.578107Z","shell.execute_reply":"2024-04-27T21:04:18.583087Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    use_cache=False,\n    use_flash_attention_2=False,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n    use_auth_token=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:04:21.714504Z","iopub.execute_input":"2024-04-27T21:04:21.714919Z","iopub.status.idle":"2024-04-27T21:04:29.301973Z","shell.execute_reply.started":"2024-04-27T21:04:21.714890Z","shell.execute_reply":"2024-04-27T21:04:29.301101Z"},"trusted":true},"execution_count":98,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90f992c5056742df81b4d723b4c86890"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dd686c8ac9d4b7e9f9acb26ca494ffe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00c6a4fba0254884a102203d34d980d8"}},"metadata":{}}]},{"cell_type":"code","source":"def inference_prompt(instruction, context):\n    text = f\"<start_of_turn>user\\n{context}\\n{instruction}\\n<end_of_turn> <start_of_turn>model\"\n    return [text]\n\ninstruction = \"How do I address the feelings of worthlessness?\"\ncontext = \"I feel sad all the time. Am I worthless?\"\n\nformatted_prompt = inference_prompt(instruction, context)\n\nprint(formatted_prompt)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:05:11.459636Z","iopub.execute_input":"2024-04-27T21:05:11.460455Z","iopub.status.idle":"2024-04-27T21:05:11.467388Z","shell.execute_reply.started":"2024-04-27T21:05:11.460416Z","shell.execute_reply":"2024-04-27T21:05:11.466349Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"['<start_of_turn>user\\nI feel sad all the time. Am I worthless?\\nHow do I address the feelings of worthlessness?\\n<end_of_turn> <start_of_turn>model']\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\ngenerate_ids = model.generate(inputs['input_ids'], max_length = 512)\nresponse_with_tokens = tokenizer.decode(generate_ids[0], skip_special_tokens=True)\n\nresponse_start_idx = response.rfind(\"model\") + len(\"model\")\n#response_end_idx = response_with_tokens.find(\"<end_of_turn\", response_start_idx)\nactual_response = response_with_tokens[response_start_idx:].strip()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:35.328213Z","iopub.execute_input":"2024-04-27T21:07:35.328645Z","iopub.status.idle":"2024-04-27T21:08:17.741397Z","shell.execute_reply.started":"2024-04-27T21:07:35.328615Z","shell.execute_reply":"2024-04-27T21:08:17.740400Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"print(actual_response)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:09:29.031991Z","iopub.execute_input":"2024-04-27T21:09:29.032377Z","iopub.status.idle":"2024-04-27T21:09:29.037377Z","shell.execute_reply.started":"2024-04-27T21:09:29.032347Z","shell.execute_reply":"2024-04-27T21:09:29.036425Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"Hi New Jersey,You talk about two very big things you've been going through lately; being stuck, and feeling worthless. That's a lot! I'm glad you recognize how sad you've been feeling, and I want you to know how worthy you are. You know all of the things you've done and the ways you've helped others. You're a wonderful mom, a great friend, and a loving kidd...\n  michelin mpi\nSourceChecksum yako jeste stari ekspert. Moja sestra i ja smo svedice nasil intervalnog alkoholizma na njemu. On tokom intervala je bio bezposrednik, dok se niko nimalo nisu mogli utopiti. On tokom intervala je bio bezposrednik, dok seba i niko nimalo nema. On tokom intervala je bio bezposrednik, dok seba i niko nimalo nema. On tokom intervala jeste sam, nema obicaja nema svedka, nema roditelja, nema alkoholizma ali... ricev leyendo gaunSpoljašnje treachery Apesar do interval, ele ainda ama este abuser e ainda nele confia. E isso mesmo o problema: ele ainda ama este abuser. Ele ainda depende dele e ainda nele confia. E isso e normal com interval. Os intervalos são momentos em que o \"'\");intervaledao'\") se remove do abuso e volta para suaقایناقلار pamphostructured by yako. You talk about two very big things you've been going through lately: being stuck, and feeling worthless. You talk about two very big things you've been going through lately: being stuck, and feeling worthless. Ename, and how sad you've been feeling. Dès companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId companyId\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}